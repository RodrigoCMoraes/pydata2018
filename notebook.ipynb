{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4b36b82268062aff9d724d615dcfc3f4725f50f4"
   },
   "source": [
    "# Import Base Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "POLYNOMIAL_ORDER = 2\n",
    "INCLUDE_BIAS = False\n",
    "\n",
    "DATASET_FILENAME = 'adult.csv'\n",
    "\n",
    "TRAIN_TEST_SPLIT = 0.3\n",
    "TREE_DEPTH = np.arange(1, 15)\n",
    "\n",
    "RSKF_SPLITS = 2\n",
    "RSKF_REPEATS = 2\n",
    "\n",
    "RSKF_SPLITS_MODEL = 10\n",
    "RSKF_REPEATS_MODEL = 1\n",
    "\n",
    "PCA_MAX_COMPONENTS = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "959a7f6b42a7fd563eb5123f63fc575f55f78c73"
   },
   "source": [
    "# Feature Engineering - preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Columns separation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "b11ae4bff72c90d89d040cfc7ce9d89c27df6d2a"
   },
   "outputs": [],
   "source": [
    "class Columns:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.names = [ 'age', 'workclass', 'fnlwgt', 'education', 'educational-num', \n",
    "                        'marital-status', 'occupation', 'relationship', 'race', \n",
    "                        'gender', 'capital-gain', 'capital-loss', 'hours-per-week', \n",
    "                        'native-country', 'income' ]\n",
    "        self.to_drop = ['fnlwgt', 'education', 'native-country']\n",
    "        self.to_encoding = [ 'workclass', 'marital-status', 'occupation',\n",
    "                               'relationship', 'race', 'gender' ]\n",
    "        self.to_normalize = [ 'age', 'educational-num', 'hours-per-week', \n",
    "                               'capital-gain', 'capital-loss' ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function: to remove nan\n",
    "\n",
    "Polynomial features can generate numbers that has no float64 representation, and it causes error during processing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_nan(X, y):\n",
    "    X_, y_ = [], []    \n",
    "    for x, yt in zip(X, y):                \n",
    "        if np.isnan(x).any() or np.isnan(yt).any():\n",
    "            continue\n",
    "        X_.append(x)\n",
    "        y_.append(yt)        \n",
    "    return np.array(X_), np.array(y_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function that applies Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "def feature_engineering(dataframe, polynomial_order=2, include_bias=False):\n",
    "    le = LabelEncoder()\n",
    "    scaler = StandardScaler()\n",
    "    pl = PolynomialFeatures(polynomial_order, include_bias=include_bias)\n",
    "    columns = Columns()\n",
    "\n",
    "    df = dataframe\n",
    "    df.drop(columns.to_drop, axis=1, inplace=True)\n",
    "    df = pd.get_dummies(df, columns=columns.to_encoding)\n",
    "    df[\"income\"] = le.fit_transform(df['income'])\n",
    "\n",
    "    X_temp = pl.fit_transform(df[columns.to_normalize])\n",
    "    X_temp = scaler.fit_transform(X_temp)\n",
    "    df.drop(columns.to_normalize, axis=1, inplace=True)\n",
    "    X = np.hstack((df.values, X_temp))\n",
    "    y = df['income']\n",
    "    columns_names = pl.get_feature_names(df.columns)\n",
    "    X, y = remove_nan(X, y)\n",
    "    return np.hstack((df.columns.values, columns_names)), X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d61f34441e1b410cc66e3a98bea6aee0e09fddd2"
   },
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "d3225d2289059df7d4f2d07db9d6df556f6d9bf2"
   },
   "outputs": [],
   "source": [
    "dataframe = pd.read_csv(DATASET_FILENAME, index_col=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering - execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_names, X, y = feature_engineering(\n",
    "                            dataframe, \n",
    "                            polynomial_order=POLYNOMIAL_ORDER, \n",
    "                            include_bias=INCLUDE_BIAS\n",
    "                      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((34189,), (14653,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, X_test, y, y_test = train_test_split(X, y, test_size=TRAIN_TEST_SPLIT, random_state=42)\n",
    "y.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "dbf1e036b05443b6e56317eb6cfc9859174980b2"
   },
   "source": [
    "# PCA: Principal Component Analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the best components number - preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "38eb131b67f9ba84a94145b9d7aabad4b84e1003"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import fbeta_score, accuracy_score\n",
    "\n",
    "param_distribution = {\n",
    "    'max_depth': TREE_DEPTH,\n",
    "}\n",
    "\n",
    "scoring = {    \n",
    "    'Accuracy': make_scorer(accuracy_score),\n",
    "    'F1_Score': make_scorer(fbeta_score, beta=1, average='micro'),    \n",
    "}\n",
    "\n",
    "def apply_pca(fold, X_train,X_test,y_train,y_test, pca_max_components, rskf_splits, rskf_repeats, debug=True):\n",
    "    results = []\n",
    "    for i in range(1, pca_max_components + 1):\n",
    "        # train\n",
    "        pca = PCA(i)\n",
    "        X_t = pca.fit_transform(X_train)\n",
    "        kf_temp = RepeatedStratifiedKFold(n_splits=rskf_splits, n_repeats=rskf_repeats)\n",
    "        search_cv = RandomizedSearchCV(DecisionTreeClassifier(), param_distribution,\n",
    "                                       scoring=scoring, n_jobs=-1, \n",
    "                                       cv=kf_temp, \n",
    "                                       refit='F1_Score') \n",
    "        search_cv.fit(X_t, y_train)\n",
    "        model = search_cv.best_estimator_        \n",
    "\n",
    "        # test\n",
    "        X_t = pca.transform(X_test)\n",
    "        y_pred = model.predict(X_t)\n",
    "\n",
    "        # model evaluation\n",
    "        f1 = fbeta_score(y_test, y_pred, beta=1)\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "        if debug:\n",
    "            print(f\"fold: {fold} - cp:{i} train: {search_cv.best_score_} test: f1={f1}, acc={acc}\")\n",
    "        results.append((fold, i, acc, f1, pca, model))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the best components number - execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f47a7fd736f47b0f18e9132f078d4d1d765a8aca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 0 - cp:1 train: 0.8041125541125541 test: f1=0.5140105078809106, acc=0.805206200643463\n",
      "fold: 0 - cp:2 train: 0.8171288171288171 test: f1=0.5315504807692306, acc=0.8176074875694648\n",
      "fold: 0 - cp:3 train: 0.8274248274248274 test: f1=0.6484121030257565, acc=0.8355074583211465\n",
      "fold: 0 - cp:4 train: 0.8285655785655786 test: f1=0.6452018614010817, acc=0.834980988593156\n",
      "fold: 0 - cp:5 train: 0.823973323973324 test: f1=0.6534272901985907, acc=0.8417665984205908\n",
      "fold: 0 - cp:6 train: 0.8912191412191413 test: f1=0.7903414254186679, acc=0.9055279321439017\n",
      "fold: 0 - cp:7 train: 0.9182169182169182 test: f1=0.8469450985252199, acc=0.9277566539923955\n",
      "fold: 0 - cp:8 train: 0.9153211653211654 test: f1=0.8398585501389239, acc=0.9258262649897631\n",
      "fold: 0 - cp:9 train: 0.9148824148824148 test: f1=0.8393508617436156, acc=0.9252997952617724\n",
      "fold: 0 - cp:10 train: 0.9232771732771733 test: f1=0.8411263239473005, acc=0.9280491371746125\n",
      "fold: 0 - cp:11 train: 0.9541652041652041 test: f1=0.9072470937422706, acc=0.9561275226674466\n",
      "fold: 0 - cp:12 train: 0.9592254592254592 test: f1=0.931420233463035, acc=0.9670078970459198\n",
      "fold: 0 - cp:13 train: 0.9762197262197262 test: f1=0.9594463331714425, acc=0.9804621234279028\n",
      "fold: 0 - cp:14 train: 0.9793494793494794 test: f1=0.9685001211533801, acc=0.9847908745247148\n",
      "fold: 0 - cp:15 train: 0.978939978939979 test: f1=0.9721580547112463, acc=0.9866042702544604\n",
      "fold: 0 - cp:16 train: 0.9774189774189774 test: f1=0.968205627969302, acc=0.9847323778882714\n",
      "fold: 0 - cp:17 train: 0.9796712296712297 test: f1=0.9706096672334223, acc=0.9858438139806961\n",
      "fold: 0 - cp:18 train: 0.976073476073476 test: f1=0.9713661732589177, acc=0.9861947937993565\n",
      "fold: 0 - cp:19 train: 0.9794957294957295 test: f1=0.9717883521007387, acc=0.9863702837086867\n",
      "fold: 0 - cp:20 train: 0.978062478062478 test: f1=0.969741159314619, acc=0.9854343375255923\n",
      "fold: 1 - cp:1 train: 0.8041825095057035 test: f1=0.5298476163847337, acc=0.8032643032643033\n",
      "fold: 1 - cp:2 train: 0.8162035682948231 test: f1=0.5621327218002007, acc=0.8212823212823213\n",
      "fold: 1 - cp:3 train: 0.831734425270547 test: f1=0.6874326105187493, acc=0.8473733473733474\n",
      "fold: 1 - cp:4 train: 0.8288973384030418 test: f1=0.6784640296090678, acc=0.8373698373698374\n",
      "fold: 1 - cp:5 train: 0.8300965194501316 test: f1=0.6888016184695942, acc=0.847022347022347\n",
      "fold: 1 - cp:6 train: 0.892834162035683 test: f1=0.7896556138778646, acc=0.9038844038844038\n",
      "fold: 1 - cp:7 train: 0.9217315004387248 test: f1=0.8422898659651761, acc=0.9263484263484264\n",
      "fold: 1 - cp:8 train: 0.9174319976601345 test: f1=0.83525493210351, acc=0.9247689247689248\n",
      "fold: 1 - cp:9 train: 0.918075460661012 test: f1=0.8486506653401319, acc=0.9288054288054288\n",
      "fold: 1 - cp:10 train: 0.9179292190699034 test: f1=0.8419604901225306, acc=0.926055926055926\n",
      "fold: 1 - cp:11 train: 0.9595788242176075 test: f1=0.9279058361942129, acc=0.9656019656019657\n",
      "fold: 1 - cp:12 train: 0.964638783269962 test: f1=0.9462443878170125, acc=0.9740844740844741\n",
      "fold: 1 - cp:13 train: 0.9821000292483182 test: f1=0.9748913568324481, acc=0.9878319878319878\n",
      "fold: 1 - cp:14 train: 0.9837671833869552 test: f1=0.9715324046032707, acc=0.9862524862524863\n",
      "fold: 1 - cp:15 train: 0.9847908745247148 test: f1=0.9724347298117789, acc=0.9867204867204867\n",
      "fold: 1 - cp:16 train: 0.9825095057034221 test: f1=0.9758700133381836, acc=0.9883584883584884\n",
      "fold: 1 - cp:17 train: 0.9827434922491957 test: f1=0.9687652513421181, acc=0.985023985023985\n",
      "fold: 1 - cp:18 train: 0.9833869552500731 test: f1=0.9700365408038977, acc=0.9856089856089856\n",
      "fold: 1 - cp:19 train: 0.9818952910207663 test: f1=0.9733849503992258, acc=0.9871299871299871\n",
      "fold: 1 - cp:20 train: 0.9831237203860778 test: f1=0.9738562091503268, acc=0.9873639873639873\n",
      "fold: 2 - cp:1 train: 0.808968058968059 test: f1=0.5581963873421161, acc=0.8097104416496052\n",
      "fold: 2 - cp:2 train: 0.8212530712530712 test: f1=0.5617249154453213, acc=0.818075460661012\n",
      "fold: 2 - cp:3 train: 0.8190885690885692 test: f1=0.6493568938574348, acc=0.829365311494589\n",
      "fold: 2 - cp:4 train: 0.8233005733005733 test: f1=0.6627465392625259, acc=0.8389587598713074\n",
      "fold: 2 - cp:5 train: 0.8285070785070785 test: f1=0.6409404548939434, acc=0.8356244515940333\n",
      "fold: 2 - cp:6 train: 0.88996138996139 test: f1=0.789107187266849, acc=0.9007897045919859\n",
      "fold: 2 - cp:7 train: 0.9170176670176671 test: f1=0.8415452818239392, acc=0.9268207078093009\n",
      "fold: 2 - cp:8 train: 0.9152919152919153 test: f1=0.8333751568381431, acc=0.9223164668031588\n",
      "fold: 2 - cp:9 train: 0.9147946647946648 test: f1=0.8302274771880223, acc=0.9227259432582626\n",
      "fold: 2 - cp:10 train: 0.915087165087165 test: f1=0.8357862122385747, acc=0.9255922784439895\n",
      "fold: 2 - cp:11 train: 0.956943956943957 test: f1=0.9359678009513356, acc=0.9692892658672126\n",
      "fold: 2 - cp:12 train: 0.9646659646659647 test: f1=0.9386114494518879, acc=0.9705176952325242\n",
      "fold: 2 - cp:13 train: 0.9786182286182287 test: f1=0.9639168995261815, acc=0.9826264989763088\n",
      "fold: 2 - cp:14 train: 0.9813092313092313 test: f1=0.9720913374411018, acc=0.9864872769815736\n",
      "fold: 2 - cp:15 train: 0.9801977301977302 test: f1=0.9738017626463842, acc=0.9873062298917812\n",
      "fold: 2 - cp:16 train: 0.9812214812214812 test: f1=0.9691448007774538, acc=0.9851418543433752\n",
      "fold: 2 - cp:17 train: 0.9819527319527319 test: f1=0.9715255058766509, acc=0.9862532904357999\n",
      "fold: 2 - cp:18 train: 0.9812799812799813 test: f1=0.9726775956284153, acc=0.986838256800234\n",
      "fold: 2 - cp:19 train: 0.9812214812214812 test: f1=0.9686781956705768, acc=0.9848493711611582\n",
      "fold: 2 - cp:20 train: 0.9812507312507313 test: f1=0.9687917425622343, acc=0.9849663644340451\n",
      "fold: 3 - cp:1 train: 0.8006434630008774 test: f1=0.5384718319282751, acc=0.7982332982332982\n",
      "fold: 3 - cp:2 train: 0.8183094472067856 test: f1=0.6034958601655934, acc=0.8235053235053235\n",
      "fold: 3 - cp:3 train: 0.8198596080725359 test: f1=0.5870731018910528, acc=0.8288288288288288\n",
      "fold: 3 - cp:4 train: 0.8269084527639661 test: f1=0.671836533727228, acc=0.844038844038844\n",
      "fold: 3 - cp:5 train: 0.8253582918982159 test: f1=0.5853588790391765, acc=0.8303498303498303\n",
      "fold: 3 - cp:6 train: 0.891547236033928 test: f1=0.7955259519919566, acc=0.9048204048204048\n",
      "fold: 3 - cp:7 train: 0.9181047089792337 test: f1=0.8557860534866284, acc=0.9324909324909325\n",
      "fold: 3 - cp:8 train: 0.91649605147704 test: f1=0.8504603135108235, acc=0.9296829296829296\n",
      "fold: 3 - cp:9 train: 0.918865165252998 test: f1=0.838906547997457, acc=0.9258804258804259\n",
      "fold: 3 - cp:10 train: 0.915911085112606 test: f1=0.8542028266798909, acc=0.9312039312039312\n",
      "fold: 3 - cp:11 train: 0.95756069026031 test: f1=0.9272817214939402, acc=0.9656019656019657\n",
      "fold: 3 - cp:12 train: 0.9630593740859901 test: f1=0.9437155119558553, acc=0.9731484731484732\n",
      "fold: 3 - cp:13 train: 0.9806083650190114 test: f1=0.9705061293846341, acc=0.9857844857844857\n",
      "fold: 3 - cp:14 train: 0.9799064053816906 test: f1=0.9684953168714268, acc=0.9848484848484849\n",
      "fold: 3 - cp:15 train: 0.9793506873354783 test: f1=0.9708171206225682, acc=0.9859599859599859\n",
      "fold: 3 - cp:16 train: 0.9809300965194502 test: f1=0.968408262454435, acc=0.9847899847899848\n",
      "fold: 3 - cp:17 train: 0.981134834747002 test: f1=0.9724881832505151, acc=0.9867204867204867\n",
      "fold: 3 - cp:18 train: 0.9814858145656625 test: f1=0.9721580547112463, acc=0.9866034866034866\n",
      "fold: 3 - cp:19 train: 0.9800233986545773 test: f1=0.975828980930402, acc=0.9883584883584884\n",
      "fold: 3 - cp:20 train: 0.980842351564785 test: f1=0.9730122231635, acc=0.986954486954487\n",
      "Best number of components: 16\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import RandomizedSearchCV, RepeatedStratifiedKFold\n",
    "\n",
    "def best_components_number(X, y, pca_max_components, rskf_splits, rskf_repeats):\n",
    "    result = []\n",
    "    kf = RepeatedStratifiedKFold(n_splits=rskf_splits, n_repeats=rskf_repeats)\n",
    "    for fold, (train_index, test_index) in enumerate(kf.split(X, y)):\n",
    "        X_tr, X_tst = X[train_index], X[test_index]\n",
    "        y_tr, y_tst = y[train_index], y[test_index]\n",
    "\n",
    "        result_ = apply_pca(fold, X_tr, X_tst, y_tr, y_tst, pca_max_components, rskf_splits, rskf_repeats)\n",
    "        result += result_ # concatenate\n",
    "    \n",
    "    # get from highest f1 score the number of components used\n",
    "    best_f1 = 0\n",
    "    best_model = None\n",
    "    for fold, n, acc, f1, pca, model in result:\n",
    "        if best_f1 < f1:\n",
    "            best_f1 = f1\n",
    "            best_model=(fold, n, acc, f1, pca, model)\n",
    "    pca_components = best_model[1]\n",
    "    return pca_components\n",
    "\n",
    "pca_components = best_components_number(X, y, PCA_MAX_COMPONENTS, RSKF_SPLITS, RSKF_REPEATS)\n",
    "print(f'Best number of components: {pca_components}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ef6405dc26571c6c19e3ac86e971343441fa1bd1"
   },
   "source": [
    "# Get best model with best pca_components number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c502a66f4e44e7f13fc6d1391efbfc58c0d1f542"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 0 - cp:16 train: 0.9890149176118821 test: f1=0.9745454545454546, acc=0.987719298245614\n",
      "fold: 1 - cp:16 train: 0.9904124280932107 test: f1=0.9818621523579202, acc=0.9912280701754386\n",
      "fold: 2 - cp:16 train: 0.9890802729931751 test: f1=0.97629179331307, acc=0.9885931558935361\n",
      "fold: 3 - cp:16 train: 0.9905427364315892 test: f1=0.976857490864799, acc=0.9888856390757531\n",
      "fold: 4 - cp:16 train: 0.989795255118622 test: f1=0.9824773413897282, acc=0.9915179877157063\n"
     ]
    }
   ],
   "source": [
    "def get_best_model(pca_components, rskf_splits, rskf_repeats):\n",
    "    result, metrics = [], []\n",
    "    kf = RepeatedStratifiedKFold(n_splits=rskf_splits, n_repeats=rskf_repeats)\n",
    "    for fold, (train_index, test_index) in enumerate(kf.split(X, y)):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        # train\n",
    "        pca = PCA(pca_components)\n",
    "        X_t = pca.fit_transform(X_train)\n",
    "        search_cv = RandomizedSearchCV(DecisionTreeClassifier(), param_distribution,\n",
    "                                       scoring=scoring, n_jobs=-1, \n",
    "                                       cv=RepeatedStratifiedKFold(\n",
    "                                           n_splits=rskf_splits, \n",
    "                                           n_repeats=rskf_repeats), \n",
    "                                       refit='F1_Score') \n",
    "        search_cv.fit(X_t, y_train)\n",
    "        model = search_cv.best_estimator_        \n",
    "\n",
    "        # test\n",
    "        X_t = pca.transform(X_test)\n",
    "        y_pred = model.predict(X_t)\n",
    "\n",
    "        # model evaluation\n",
    "        f1 = fbeta_score(y_test, y_pred, beta=1)\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "        print(f\"fold: {fold} - cp:{pca_components} train: {search_cv.best_score_} test: f1={f1}, acc={acc}\")\n",
    "\n",
    "        result.append((X_train, y_train, X_test, y_test, fold, acc, f1, pca, model))        \n",
    "        metrics.append((f1, acc))\n",
    "\n",
    "    best_f1 = 0\n",
    "    best_model = None\n",
    "    for X_train, y_train, X_test, y_test, fold, acc, f1, pca, model in result:\n",
    "        if best_f1 < f1:\n",
    "            best_f1 = f1\n",
    "            best_model=(X_train, y_train, X_test, y_test, metrics, fold, acc, f1, pca, model)\n",
    "    return best_model\n",
    "\n",
    "best_model = get_best_model(pca_components,  RSKF_SPLITS_MODEL, RSKF_REPEATS_MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1a2c76ade55979c4ddc387093d6fafe01840b18d"
   },
   "source": [
    "# Analyse Model Result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "43d1d55b9bd731b5cc863d0ed9bd4d474c063068"
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "pca, model = best_model[-2], best_model[-1]\n",
    "probs = model.predict_proba(pca.transform(X_test))\n",
    "preds = probs[:,1]\n",
    "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "# method I: plt\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score by Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4a9e15ff7bbc044683af39c2f6320d80ad0fe106"
   },
   "outputs": [],
   "source": [
    "f1_r, acc_r = [], []\n",
    "for f1, acc in best_model[4]:\n",
    "    f1_r.append(f1)\n",
    "    acc_r.append(acc)\n",
    "\n",
    "f1_r, acc_r = np.array(f1_r), np.array(acc_r)\n",
    "l = f1_r.shape[0]\n",
    "plt.title(f'F1 Score in Folds(PCA components = {pca_components})')\n",
    "plt.plot(range(l), f1_r, 'r', label = 'F1 Score')\n",
    "plt.plot(range(l), acc_r, 'b', label = 'Accuracy')\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.xticks(range(l))\n",
    "plt.xlim([0, l - 1])\n",
    "plt.ylim([0.60, 1])\n",
    "plt.ylabel('F1 Score')\n",
    "plt.xlabel('Fold')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "84ef8ca79b28a3631c3ebfbd963fdaa41611f495"
   },
   "source": [
    "## Plot feature importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0f2780a18ccf9b5d494491f85924f084eaf40002"
   },
   "outputs": [],
   "source": [
    "def plot_feature_importances(clf, X_train, y_train=None, \n",
    "                             top_n=10, figsize=(8,8), print_table=False, title=\"Feature Importances\"):\n",
    "#     https://www.kaggle.com/grfiv4/plotting-feature-importances\n",
    "    __name__ = \"plot_feature_importances\"\n",
    "    \n",
    "    import pandas as pd\n",
    "    import numpy  as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    X_train = pd.DataFrame(data=X_train, columns=[f\"PC{i}\" for i in range(1, X_train.shape[1] + 1)])\n",
    "    \n",
    "    feat_imp = pd.DataFrame({'importance':clf.feature_importances_})    \n",
    "    feat_imp['feature'] = X_train.columns\n",
    "    feat_imp.sort_values(by='importance', ascending=False, inplace=True)\n",
    "    feat_imp = feat_imp.iloc[:top_n]\n",
    "    \n",
    "    feat_imp.sort_values(by='importance', inplace=True)\n",
    "    feat_imp = feat_imp.set_index('feature', drop=True)\n",
    "    feat_imp.plot.barh(title=title, figsize=figsize)\n",
    "    plt.xlabel('Feature Importance Score')\n",
    "    plt.show()\n",
    "    \n",
    "    if print_table:\n",
    "        from IPython.display import display\n",
    "        print(\"Top {} features in descending order of importance\".format(top_n))\n",
    "        display(feat_imp.sort_values(by='importance', ascending=False))\n",
    "        \n",
    "    return feat_imp\n",
    "\n",
    "pca, clf = best_model[-2], best_model[-1]\n",
    "feature_importance = plot_feature_importances(clf, pca.transform(X), top_n=X.shape[1], title=clf.__class__.__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4d45da269ae5cc08ae411f0babe1b59bb26c808b"
   },
   "source": [
    "## Get Features Used to Generate PCA Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "47c86e3fa7517d67fb61d2f1d0fecea1699aef8c"
   },
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/22348668/pca-decomposition-with-python-features-relevances\n",
    "pca, clf = best_model[-2], best_model[-1]\n",
    "index_components = [int(x[2:]) for x in feature_importance.index.values]\n",
    "def features_used_to_generate_pca_components(index_components, pca, clf, columns_names):    \n",
    "    for i in index_components:\n",
    "        index_features = np.abs(pca.components_[i - 1]).argsort()[:4]\n",
    "        features = columns_names[index_features]\n",
    "        print(f'PC{i}')\n",
    "        print(f'Features:')\n",
    "        for f in features:\n",
    "            print(\"\\t\" + f)\n",
    "        print()\n",
    "        \n",
    "features_used_to_generate_pca_components(index_components, pca, clf, columns_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d83aa9db019f6ebc52301363a9e71d0aa96fb820"
   },
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "932a033a6647e655e3945dd42aa6c8f86f780b61"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "pca, clf = best_model[-2], best_model[-1]\n",
    "\n",
    "y_pred = clf.predict(pca.transform(X_test))\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d517b07b21c91f1483c2848dbd290e5ea52e897f"
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "plot_confusion_matrix(cm, [0, 1], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "bb906c8d2e4c136aeaa18e0acc122432320c529e"
   },
   "source": [
    "## Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e82a1d26eb772c17515ff8d90573240bc4f507af"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "628888d7084883298524538267dea8f2e08ca241"
   },
   "source": [
    "# Save Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "259e6a49fca2d23aa119e554a9e66c07cb6bd282"
   },
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "\n",
    "joblib.dump(best_model, 'lgr.joblib')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "373px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
